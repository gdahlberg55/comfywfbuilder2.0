{
  "workflow_metadata": {
    "name": "Outfit Variation Workflow",
    "version": "2.1",
    "type": "outfit_variation_with_animation",
    "total_nodes": 77,
    "total_links": 90,
    "complexity_score": 8.5
  },
  
  "semantic_groups": [
    {
      "group_id": "sg_0_loaders",
      "title": "(0) Model & Resource Loaders",
      "bounding": [0, -2200, 2000, 2800],
      "color": "#355335",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Load all base models, CLIP, VAE, and vision models",
        "collapsible": true,
        "category": "initialization"
      },
      "node_count": 6
    },
    {
      "group_id": "sg_1_lora",
      "title": "(1) LoRA Application Chain",
      "bounding": [2500, -2200, 4000, 1200],
      "color": "#355335",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Apply LoRA models in sequence for outfit variations",
        "collapsible": true,
        "category": "model_modification"
      },
      "node_count": 3
    },
    {
      "group_id": "sg_2_conditioning",
      "title": "(2) Text Encoding & Conditioning",
      "bounding": [7000, -1600, 4000, 2200],
      "color": "#353553",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Process text prompts and create conditioning",
        "collapsible": true,
        "category": "prompt_processing"
      },
      "node_count": 5
    },
    {
      "group_id": "sg_3_image_prep",
      "title": "(3) Image Preparation & Masking",
      "bounding": [11500, -1200, 4000, 2400],
      "color": "#453553",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Prepare input images, apply masks, resize and crop",
        "collapsible": true,
        "category": "preprocessing"
      },
      "node_count": 6
    },
    {
      "group_id": "sg_4_control",
      "title": "(4) Seeds & Control Parameters",
      "bounding": [16000, -800, 4000, 2400],
      "color": "#534535",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Control parameters, seeds, and variation settings",
        "collapsible": true,
        "category": "control_logic"
      },
      "node_count": 6
    },
    {
      "group_id": "sg_5_sampling",
      "title": "(5) Sampling & Generation",
      "bounding": [20500, -1600, 4000, 2400],
      "color": "#533535",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Core image generation and sampling operations",
        "collapsible": true,
        "category": "generation"
      },
      "node_count": 9
    },
    {
      "group_id": "sg_6_video",
      "title": "(6) Video Enhancement & Combination",
      "bounding": [25000, -1200, 4000, 2400],
      "color": "#533545",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Video processing, frame interpolation, and enhancement",
        "collapsible": true,
        "category": "post_processing"
      },
      "node_count": 9
    },
    {
      "group_id": "sg_7_output",
      "title": "(7) Preview & Save Operations",
      "bounding": [29500, -800, 3000, 2400],
      "color": "#355353",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 3,
        "padding": 50,
        "border_style": "solid"
      },
      "metadata": {
        "purpose": "Final outputs, previews, and save operations",
        "collapsible": true,
        "category": "output"
      },
      "node_count": 8
    },
    {
      "group_id": "sg_8_docs",
      "title": "(8) Workflow Documentation",
      "bounding": [33000, -2200, 7000, 4400],
      "color": "#444444",
      "locked": false,
      "font_size": 24,
      "style": {
        "border_width": 2,
        "padding": 80,
        "border_style": "dashed"
      },
      "metadata": {
        "purpose": "Notes and documentation for workflow usage",
        "collapsible": true,
        "category": "documentation"
      },
      "node_count": 16
    }
  ],
  
  "data_bus_connections": {
    "MODEL": {
      "color": "#FFB6C1",
      "y_position": -2000,
      "description": "Main model pipeline through LoRA chain"
    },
    "CLIP": {
      "color": "#98D8C8",
      "y_position": -1600,
      "description": "CLIP text encoder connections"
    },
    "VAE": {
      "color": "#F7DC6F",
      "y_position": -1200,
      "description": "VAE encode/decode operations"
    },
    "IMAGE": {
      "color": "#BB8FCE",
      "y_position": -800,
      "description": "Image data flow"
    },
    "LATENT": {
      "color": "#85C1E2",
      "y_position": -400,
      "description": "Latent space operations"
    },
    "CONDITIONING": {
      "color": "#F8C471",
      "y_position": 0,
      "description": "Positive/negative conditioning"
    }
  },
  
  "group_hierarchy": {
    "primary_flow": ["sg_0_loaders", "sg_1_lora", "sg_2_conditioning", "sg_5_sampling", "sg_7_output"],
    "secondary_flow": ["sg_3_image_prep", "sg_4_control", "sg_6_video"],
    "support": ["sg_8_docs"]
  },
  
  "validation": {
    "all_nodes_grouped": true,
    "color_scheme_compliant": true,
    "spacing_applied": true,
    "gold_standard_ready": true
  }
}