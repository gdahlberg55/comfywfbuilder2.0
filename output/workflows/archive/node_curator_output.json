{
  "selected_nodes": [
    {
      "node_id": "checkpoint_loader_1",
      "class_type": "CheckpointLoaderSimple",
      "category": "Model Loading",
      "inputs": {
        "ckpt_name": "SD1.5 or SDXL checkpoint"
      },
      "outputs": ["MODEL", "CLIP", "VAE"],
      "meta": {
        "title": "Base Model Loader",
        "description": "Loads the main diffusion model"
      }
    },
    {
      "node_id": "lora_loader_fashion_1",
      "class_type": "LoraLoader",
      "category": "Model Enhancement",
      "inputs": {
        "model": "MODEL",
        "clip": "CLIP",
        "lora_name": "fashion_lora.safetensors",
        "strength_model": 0.8,
        "strength_clip": 0.8
      },
      "outputs": ["MODEL", "CLIP"],
      "meta": {
        "title": "Fashion LoRA 1",
        "description": "Applies fashion-specific LoRA"
      }
    },
    {
      "node_id": "image_load_pose",
      "class_type": "LoadImage",
      "category": "Image Input",
      "inputs": {
        "image": "input_pose_image.png"
      },
      "outputs": ["IMAGE", "MASK"],
      "meta": {
        "title": "Pose Reference Image",
        "description": "Loads the source pose image"
      }
    },
    {
      "node_id": "openpose_preprocessor",
      "class_type": "OpenposePreprocessor",
      "category": "Preprocessing",
      "inputs": {
        "image": "IMAGE",
        "detect_hand": true,
        "detect_body": true,
        "detect_face": true
      },
      "outputs": ["IMAGE"],
      "meta": {
        "title": "OpenPose Detector",
        "description": "Extracts pose keypoints"
      }
    },
    {
      "node_id": "controlnet_loader_openpose",
      "class_type": "ControlNetLoader",
      "category": "ControlNet",
      "inputs": {
        "control_net_name": "control_openpose-fp16.safetensors"
      },
      "outputs": ["CONTROL_NET"],
      "meta": {
        "title": "OpenPose ControlNet",
        "description": "Loads OpenPose control model"
      }
    },
    {
      "node_id": "controlnet_apply_1",
      "class_type": "ControlNetApplyAdvanced",
      "category": "ControlNet",
      "inputs": {
        "positive": "CONDITIONING",
        "negative": "CONDITIONING",
        "control_net": "CONTROL_NET",
        "image": "IMAGE",
        "strength": 1.0,
        "start_percent": 0.0,
        "end_percent": 1.0
      },
      "outputs": ["CONDITIONING", "CONDITIONING"],
      "meta": {
        "title": "Apply OpenPose Control",
        "description": "Applies pose conditioning"
      }
    },
    {
      "node_id": "ipadapter_model_loader",
      "class_type": "IPAdapterModelLoader",
      "category": "IP-Adapter",
      "inputs": {
        "ipadapter_file": "ip-adapter_sd15.safetensors"
      },
      "outputs": ["IPADAPTER"],
      "meta": {
        "title": "IP-Adapter Model",
        "description": "Loads IP-Adapter for style transfer"
      }
    },
    {
      "node_id": "clip_vision_loader",
      "class_type": "CLIPVisionLoader",
      "category": "IP-Adapter",
      "inputs": {
        "clip_name": "clip_vision_g.safetensors"
      },
      "outputs": ["CLIP_VISION"],
      "meta": {
        "title": "CLIP Vision Encoder",
        "description": "For IP-Adapter image encoding"
      }
    },
    {
      "node_id": "image_load_style",
      "class_type": "LoadImage",
      "category": "Image Input",
      "inputs": {
        "image": "style_reference.png"
      },
      "outputs": ["IMAGE", "MASK"],
      "meta": {
        "title": "Style Reference Image",
        "description": "Outfit style reference"
      }
    },
    {
      "node_id": "ipadapter_apply",
      "class_type": "IPAdapterApply",
      "category": "IP-Adapter",
      "inputs": {
        "ipadapter": "IPADAPTER",
        "clip_vision": "CLIP_VISION",
        "image": "IMAGE",
        "model": "MODEL",
        "weight": 0.8,
        "weight_type": "linear"
      },
      "outputs": ["MODEL"],
      "meta": {
        "title": "Apply Style Transfer",
        "description": "Applies outfit style to model"
      }
    },
    {
      "node_id": "clip_text_positive",
      "class_type": "CLIPTextEncode",
      "category": "Conditioning",
      "inputs": {
        "text": "fashion photography, professional model, high quality outfit",
        "clip": "CLIP"
      },
      "outputs": ["CONDITIONING"],
      "meta": {
        "title": "Positive Prompt",
        "description": "Main positive conditioning"
      }
    },
    {
      "node_id": "clip_text_negative",
      "class_type": "CLIPTextEncode",
      "category": "Conditioning",
      "inputs": {
        "text": "low quality, blurry, distorted",
        "clip": "CLIP"
      },
      "outputs": ["CONDITIONING"],
      "meta": {
        "title": "Negative Prompt",
        "description": "Negative conditioning"
      }
    },
    {
      "node_id": "empty_latent",
      "class_type": "EmptyLatentImage",
      "category": "Latent",
      "inputs": {
        "width": 512,
        "height": 768,
        "batch_size": 1
      },
      "outputs": ["LATENT"],
      "meta": {
        "title": "Latent Image",
        "description": "Initial latent for generation"
      }
    },
    {
      "node_id": "ksampler_branch_1",
      "class_type": "KSampler",
      "category": "Sampling",
      "inputs": {
        "model": "MODEL",
        "positive": "CONDITIONING",
        "negative": "CONDITIONING",
        "latent_image": "LATENT",
        "seed": 123456,
        "steps": 20,
        "cfg": 7.5,
        "sampler_name": "euler",
        "scheduler": "normal",
        "denoise": 1.0
      },
      "outputs": ["LATENT"],
      "meta": {
        "title": "Variation 1 Sampler",
        "description": "First outfit variation"
      }
    },
    {
      "node_id": "ksampler_branch_2",
      "class_type": "KSampler",
      "category": "Sampling",
      "inputs": {
        "model": "MODEL",
        "positive": "CONDITIONING",
        "negative": "CONDITIONING",
        "latent_image": "LATENT",
        "seed": 789012,
        "steps": 20,
        "cfg": 7.5,
        "sampler_name": "euler",
        "scheduler": "normal",
        "denoise": 1.0
      },
      "outputs": ["LATENT"],
      "meta": {
        "title": "Variation 2 Sampler",
        "description": "Second outfit variation"
      }
    },
    {
      "node_id": "ksampler_branch_3",
      "class_type": "KSampler",
      "category": "Sampling",
      "inputs": {
        "model": "MODEL",
        "positive": "CONDITIONING",
        "negative": "CONDITIONING",
        "latent_image": "LATENT",
        "seed": 345678,
        "steps": 20,
        "cfg": 7.5,
        "sampler_name": "euler",
        "scheduler": "normal",
        "denoise": 1.0
      },
      "outputs": ["LATENT"],
      "meta": {
        "title": "Variation 3 Sampler",
        "description": "Third outfit variation"
      }
    },
    {
      "node_id": "vae_decode_1",
      "class_type": "VAEDecode",
      "category": "Latent",
      "inputs": {
        "samples": "LATENT",
        "vae": "VAE"
      },
      "outputs": ["IMAGE"],
      "meta": {
        "title": "Decode Variation 1",
        "description": "Converts latent to image"
      }
    },
    {
      "node_id": "vae_decode_2",
      "class_type": "VAEDecode",
      "category": "Latent",
      "inputs": {
        "samples": "LATENT",
        "vae": "VAE"
      },
      "outputs": ["IMAGE"],
      "meta": {
        "title": "Decode Variation 2",
        "description": "Converts latent to image"
      }
    },
    {
      "node_id": "vae_decode_3",
      "class_type": "VAEDecode",
      "category": "Latent",
      "inputs": {
        "samples": "LATENT",
        "vae": "VAE"
      },
      "outputs": ["IMAGE"],
      "meta": {
        "title": "Decode Variation 3",
        "description": "Converts latent to image"
      }
    },
    {
      "node_id": "image_preview_1",
      "class_type": "PreviewImage",
      "category": "Output",
      "inputs": {
        "images": "IMAGE"
      },
      "outputs": [],
      "meta": {
        "title": "Preview Variation 1",
        "description": "Shows first outfit"
      }
    },
    {
      "node_id": "image_preview_2",
      "class_type": "PreviewImage",
      "category": "Output",
      "inputs": {
        "images": "IMAGE"
      },
      "outputs": [],
      "meta": {
        "title": "Preview Variation 2",
        "description": "Shows second outfit"
      }
    },
    {
      "node_id": "image_preview_3",
      "class_type": "PreviewImage",
      "category": "Output",
      "inputs": {
        "images": "IMAGE"
      },
      "outputs": [],
      "meta": {
        "title": "Preview Variation 3",
        "description": "Shows third outfit"
      }
    },
    {
      "node_id": "image_save_batch",
      "class_type": "SaveImage",
      "category": "Output",
      "inputs": {
        "images": "IMAGE",
        "filename_prefix": "outfit_variation"
      },
      "outputs": [],
      "meta": {
        "title": "Save All Variations",
        "description": "Saves generated outfits"
      }
    }
  ],
  "node_connections": {
    "model_flow": [
      "checkpoint_loader_1 -> lora_loader_fashion_1 -> ipadapter_apply -> ksampler_branches"
    ],
    "conditioning_flow": [
      "clip_text_positive/negative -> controlnet_apply_1 -> ksampler_branches"
    ],
    "control_flow": [
      "image_load_pose -> openpose_preprocessor -> controlnet_apply_1"
    ],
    "style_flow": [
      "image_load_style -> ipadapter_apply"
    ],
    "generation_branches": [
      "Three parallel KSampler nodes with different seeds for variations"
    ]
  },
  "additional_recommendations": [
    "Consider adding a LoRA strength slider for fine-tuning fashion influence",
    "Add seed randomization nodes for more variations",
    "Include image comparison node to display all variations side by side",
    "Consider adding prompt variation nodes for different outfit descriptions",
    "Add upscaling nodes if higher resolution outputs are needed"
  ]
}